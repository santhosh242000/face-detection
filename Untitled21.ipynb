{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aNz27TAXSu6Z"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Facial Recognition with FaceNet\n",
        "#Blurriness and Lighting Check"
      ],
      "metadata": {
        "id": "x7yYosIZTmg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained FaceNet model\n",
        "facenet_model = load_model('facenet_keras.h5')\n",
        "\n",
        "# Function to compute embeddings\n",
        "def get_embedding(model, face_pixels):\n",
        "    face_pixels = face_pixels.astype('float32')\n",
        "    mean, std = face_pixels.mean(), face_pixels.std()\n",
        "    face_pixels = (face_pixels - mean) / std\n",
        "    sample = np.expand_dims(face_pixels, axis=0)\n",
        "    return model.predict(sample)[0]\n",
        "\n",
        "# Blurriness Detection\n",
        "def is_blurry(image, threshold=100):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    return laplacian_var < threshold\n",
        "\n",
        "# Low Light Detection\n",
        "def is_low_light(image, threshold=50):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return gray.mean() < threshold\n",
        "\n",
        "# Attendance Logging\n",
        "attendance_log = {}\n",
        "\n",
        "def log_attendance(name, confidence):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    attendance_log[name] = {\"timestamp\": timestamp, \"confidence\": confidence}\n",
        "    print(f\"Attendance logged for {name} with {confidence*100:.2f}% confidence at {timestamp}.\")\n"
      ],
      "metadata": {
        "id": "FNle9J-OTt3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Real-Time Face Presence Tracking\n",
        "#Multiple Face Detection\n",
        "#Suspicious Behavior Detection\n",
        "\n",
        "\n",
        "\n",
        "def start_test_proctoring(face_database, session_duration=16*60*60):\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    start_time = datetime.now()\n",
        "    end_time = start_time + timedelta(seconds=session_duration)\n",
        "\n",
        "    no_face_start_time = None\n",
        "    face_absence_limit = 30  # seconds\n",
        "    suspicious_events = []\n",
        "\n",
        "    while datetime.now() < end_time:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture frame. Exiting...\")\n",
        "            break\n",
        "\n",
        "        faces = detect_face(frame)  # Detect faces\n",
        "        face_present = len(faces) > 0\n",
        "\n",
        "        if face_present:\n",
        "            # Reset absence timer\n",
        "            no_face_start_time = None\n",
        "\n",
        "            # Check multiple faces\n",
        "            if len(faces) > 1:\n",
        "                suspicious_events.append(\"Multiple faces detected\")\n",
        "                cv2.putText(frame, \"ALERT: Multiple faces detected!\", (10, 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "            # Recognize each face and check for quality\n",
        "            for face in faces:\n",
        "                x, y, w, h = face\n",
        "                face_img = frame[y:y+h, x:x+w]\n",
        "                face_img_resized = cv2.resize(face_img, (160, 160))\n",
        "\n",
        "                # Check for image quality\n",
        "                if is_blurry(face_img):\n",
        "                    cv2.putText(frame, \"Blurry Image\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "                    continue\n",
        "                if is_low_light(face_img):\n",
        "                    cv2.putText(frame, \"Low Light\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "                    continue\n",
        "\n",
        "                # Recognize face\n",
        "                embedding = get_embedding(facenet_model, face_img_resized)\n",
        "                recognized = False\n",
        "                for name, db_embedding in face_database.items():\n",
        "                    similarity = np.dot(embedding, db_embedding) / (\n",
        "                            np.linalg.norm(embedding) * np.linalg.norm(db_embedding))\n",
        "                    if similarity > 0.5:\n",
        "                        recognized = True\n",
        "                        cv2.putText(frame, f\"Recognized: {name}\", (x, y - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "                        break\n",
        "\n",
        "                if not recognized:\n",
        "                    cv2.putText(frame, \"Unknown\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "        else:\n",
        "            # Track absence of face\n",
        "            if no_face_start_time is None:\n",
        "                no_face_start_time = time.time()\n",
        "            elif time.time() - no_face_start_time > face_absence_limit:\n",
        "                suspicious_events.append(\"Face absent for more than 30 seconds\")\n",
        "                cv2.putText(frame, \"ALERT: No face detected!\", (10, 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        # Display the frame\n",
        "        cv2.imshow(\"Test Proctoring\", frame)\n",
        "\n",
        "        # Exit condition\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(\"Test session ended.\")\n",
        "    print(\"Suspicious Events Log:\")\n",
        "    for event in suspicious_events:\n",
        "        print(event)\n"
      ],
      "metadata": {
        "id": "d6oipjIdTwzI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utility Function for Face Detection\n",
        "def detect_face(image):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    return faces\n"
      ],
      "metadata": {
        "id": "horvabFgUDu9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lKQIKYxUPh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}